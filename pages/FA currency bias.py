import requests
from bs4 import BeautifulSoup
import pandas as pd
import streamlit as st

def fetch_html(url, headers=None):
    """L·∫•y n·ªôi dung HTML t·ª´ m·ªôt URL."""
    response = requests.get(url, headers=headers)
    if response.status_code == 200:
        return response.text
    else:
        st.error(f"L·ªói: {response.status_code}")
        return None

def parse_html(html):
    """Ph√¢n t√≠ch HTML b·∫±ng BeautifulSoup."""
    soup = BeautifulSoup(html, 'html.parser')
    return soup

def extract_table_data(soup, table_selector):
    """Tr√≠ch xu·∫•t d·ªØ li·ªáu t·ª´ m·ªôt b·∫£ng HTML."""
    table = soup.select_one(table_selector)
    if not table:
        st.warning("Kh√¥ng t√¨m th·∫•y b·∫£ng!")
        return []

    data = []
    for row in table.find_all("tr"):
        cells = [cell.get_text(strip=True) for cell in row.find_all(["th", "td"])]
        data.append(cells)

    return data

def main():
    st.title("üìä Ph√¢n t√≠ch c∆° b·∫£n FX")
    
    url = "https://fundamentaltrades.com/fundamental-bias/bias-scorecard/"
    headers = {"User-Agent": "Mozilla/5.0"}

    html = fetch_html(url, headers)
    if html:
        soup = parse_html(html)
        table_data = extract_table_data(soup, "table")  # ƒêi·ªÅu ch·ªânh selector n·∫øu c·∫ßn

        if table_data:
            # Chuy·ªÉn d·ªØ li·ªáu th√†nh DataFrame
            df = pd.DataFrame(table_data[1:], columns=table_data[0])
            
            # Hi·ªÉn th·ªã b·∫£ng tr√™n Streamlit
            st.write("### D·ªØ li·ªáu t·ª´ b·∫£ng:")
            st.dataframe(df)

            # T·∫£i xu·ªëng file CSV
            csv = df.to_csv(index=False).encode("utf-8")
            st.download_button("üì• T·∫£i xu·ªëng CSV", data=csv, file_name="bias_scorecard.csv", mime="text/csv")

if __name__ == "__main__":
    main()